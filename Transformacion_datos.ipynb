{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación de Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"C:/Users/jano_/OneDrive/Escritorio/Proyecto Final Henry/Movies/movies_dataset.csv\") #apertura csv movie_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminación de columnas que no serán necesarias para desarrollar el modelo\n",
    "\n",
    "df_movies.drop([\"video\", \"imdb_id\", \"adult\", \"original_title\", \"homepage\", \"poster_path\", \"status\", \"spoken_languages\", \"production_countries\"], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Se eliminan filas donde en release_date hayan nulos ya que será un parámetro fundamental para desarrollar las funciones de la API, \n",
    "además se realiza lo mismo sobre la columna popularity ya que será un argumento de recorte del dataset.\"\"\"\n",
    "\n",
    "df_movies.dropna(subset= [\"release_date\"], inplace= True)\n",
    "df_movies.dropna(subset= [\"popularity\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorte del dataset según la popularidad de las peliculas que contiene el mismo\n",
    "\n",
    "popularity_min = 8.0\n",
    "df_movies[\"popularity\"] = pd.to_numeric(df_movies[\"popularity\"], errors= \"coerce\")\n",
    "df_movies = df_movies[df_movies[\"popularity\"] >= popularity_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A continuación tomamos los valores de belongs_to_collections cómo diccionarios(para esto implementamos la librería ast ya que son datos tipo string) \n",
    " y desanidamos los valores en un nueva tabla para colecciones, a su vez convertimos los valores de id en enteros. \"\"\"\n",
    "\n",
    "df_movies[\"belongs_to_collection\"] = df_movies[\"belongs_to_collection\"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else x)\n",
    "\n",
    "df_collection = df_movies[\"belongs_to_collection\"].apply(lambda x: {\n",
    "    \"idCollection\": x[\"id\"],\n",
    "    \"nameCollection\": x[\"name\"]\n",
    "}\n",
    "if isinstance(x, dict) else None).apply(pd.Series)\n",
    "\n",
    "df_collection['idCollection'] = df_collection['idCollection'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos id de df_movies y a este mismo dataframe le concatenamos idCollections para consultas.\n",
    "df_movies = df_movies.rename(columns={\"id\" : \"idMovies\"})\n",
    "df_movies['idMovies'] = df_movies['idMovies'].astype(int)\n",
    "df_movies = pd.concat([df_movies , df_collection[\"idCollection\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan duplicados de df_collections, ya fueron copiados los idCollection en cada pelicula de df_movies y filas con valores nulos\n",
    "df_collection = df_collection.drop_duplicates(subset='idCollection', keep='first')\n",
    "df_collection.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection.to_parquet(\"Collections.parquet\", engine= \"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Se desanida genres de df_movies con función explode, \n",
    "que separará cada elemento de las listas contenidas en la columna genres y duplicará en filas por cada elemento.\"\"\"\n",
    "\n",
    "df_movies[\"genres\"] = df_movies[\"genres\"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else x)\n",
    "df_aux_genres = df_movies.explode(\"genres\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la tabla df_genres, que contendra id y nombre de los géneros.\n",
    "\n",
    "df_genres= df_aux_genres[\"genres\"].apply(lambda x: {\n",
    "    \"idGenres\": x[\"id\"],\n",
    "    \"nameGenres\": x[\"name\"]\n",
    "}\n",
    "if isinstance(x, dict) else None).apply(pd.Series)\n",
    "\n",
    "df_genres[\"idGenres\"] = df_genres[\"idGenres\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una tabla complementaria para poder relacionar la entidad Género y Movie del modelo.\n",
    "\n",
    "df_genres_movies = pd.concat([df_genres[\"idGenres\"], df_aux_genres[\"idMovies\"]], axis= 1)\n",
    "del df_aux_genres\n",
    "df_genres_movies.to_parquet(\"DataSet/Relation_Movies_Genres.parquet\", engine= \"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan duplicados de la tabla df_genres y guardamos el data frame cómo un archivo parquet.\n",
    "\n",
    "df_genres = df_genres.drop_duplicates(subset='idGenres', keep='first')\n",
    "df_genres.to_parquet(\"Genres.parquet\", engine=\"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Se desanida production_companies de df_movies con función explode, \n",
    "que separará cada elemento de las listas contenidas en la columna production_companies y duplicará en filas por cada elemento.\"\"\"\n",
    "\n",
    "df_movies[\"production_companies\"] = df_movies[\"production_companies\"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else x)\n",
    "df_aux_companies = df_movies.explode(\"production_companies\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la tabla df_prod_companies, que contendra id y nombre de las compañías productoras.\n",
    "\n",
    "df_prod_companies= df_aux_companies[\"production_companies\"].apply(lambda x: {\n",
    "    \"idCompany\": x[\"id\"],\n",
    "    \"nameCompany\": x[\"name\"]\n",
    "}\n",
    "if isinstance(x, dict) else None).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una tabla complementaria para poder relacionar la entidad Production_companies y Movies del modelo.\n",
    "\n",
    "df_prod_company_movies = pd.concat([df_prod_companies[\"idCompany\"], df_aux_companies[\"idMovies\"]], axis= 1)\n",
    "del df_aux_companies\n",
    "df_prod_company_movies.dropna(inplace=True)\n",
    "df_prod_company_movies.to_parquet(\"DataSet/Relation_Movies_Companies.parquet\", engine= \"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan duplicados y valorez nulos de la tabla df_prod_companies y guardamos el data frame cómo un archivo parquet.\n",
    "\n",
    "df_prod_companies.dropna(inplace=True)\n",
    "df_prod_companies = df_prod_companies.drop_duplicates(subset='idCompany', keep='first')\n",
    "df_prod_companies.to_parquet(\"Production_companies.parquet\", engine=\"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas desanidadas.\n",
    "df_movies.drop(columns= [\"belongs_to_collection\"], inplace= True)\n",
    "#df_movies.drop(columns= [\"genres\",\"production_companies\", \"belongs_to_collection\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos valores nulos por 0 en las columnas revenue y budget, a su vez creamos columna con el retorno dividiendo revenue por budget,\n",
    "# siempre que ninguno de las dos contenga 0.\n",
    "df_movies[\"revenue\"] = pd.to_numeric(df_movies[\"revenue\"], errors=\"coerce\")\n",
    "df_movies[\"budget\"] = pd.to_numeric(df_movies[\"budget\"], errors=\"coerce\")\n",
    "df_movies [[\"revenue\", \"budget\"]] = df_movies [[\"revenue\", \"budget\"]].fillna(0)\n",
    "df_movies[\"return\"] = np.where(\n",
    "    (df_movies[\"revenue\"] != 0) & (df_movies[\"budget\"] != 0),\n",
    "    df_movies[\"revenue\"] / df_movies[\"budget\"],\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el formato a la columna release_date y agregamos una columna nueva donde extraemos el año de estreno para luego usarla en el modelo de ML.\n",
    "\n",
    "df_movies[\"release_date\"] = pd.to_datetime(df_movies[\"release_date\"], format= \"%Y-%m-%d\")\n",
    "df_movies[\"release_year\"] = df_movies [\"release_date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_parquet(\"Movies.parquet\", engine= \"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación de Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits = pd.read_csv(\"C:/Users/jano_/OneDrive/Escritorio/Proyecto Final Henry/Movies/credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza recorte del dataset según las películas que recortamos en movie, por popolarity > 8.0\n",
    "df_credits = df_credits.rename(columns={\"id\" : \"idMovies\"})\n",
    "df_credits_short = df_credits[df_credits[\"idMovies\"].isin(df_movies[\"idMovies\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"La primer línea del código toma los valores como listas y/o diccionario de python para poder luego desanidar con explode,\n",
    " a su vez recortamos la cantidad de actores según el orden en que aparecen primero ya que se observó que los actores principales son los primeros\n",
    " en aparecer.\"\"\"\n",
    " \n",
    "df_credits_short[\"cast\"] = df_credits_short[\"cast\"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else x)\n",
    "df_cast_aux = df_credits_short.explode(\"cast\").reset_index(drop=True)\n",
    "df_cast_aux = df_cast_aux.groupby(\"idMovies\").head(15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cast= df_cast_aux[\"cast\"].apply(lambda x: {\n",
    "    \"idCast\": x[\"id\"],\n",
    "    \"nameCast\": x[\"name\"]\n",
    "}\n",
    "if isinstance(x, dict) else None).apply(pd.Series)\n",
    "\n",
    "df_cast[\"idCast\"] = df_cast[\"idCast\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cast_movies = pd.concat([df_cast[\"idCast\"], df_cast_aux[\"idMovies\"]], axis= 1)\n",
    "df_cast_movies.to_parquet(\"DataSet/Relation_Cast_Movies.parquet\", engine= \"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cast = df_cast.drop_duplicates(subset='idCast', keep='first')\n",
    "df_cast.to_parquet(\"DataSet/Cast_Movies.parquet\", engine= \"pyarrow\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits_short[\"crew\"] = df_credits_short[\"crew\"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else x)\n",
    "df_crew_aux = df_credits_short.explode(\"crew\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew= df_crew_aux[\"crew\"].apply(lambda x: {\n",
    "    \"idCrew\": x[\"id\"],\n",
    "    \"nameCrew\": x[\"name\"],\n",
    "    \"nameJob\": x[\"job\"],\n",
    "}\n",
    "if isinstance(x, dict) else None).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew[\"idCrew\"] = df_crew[\"idCrew\"].astype(\"Int64\")\n",
    "df_crew = pd.concat([df_crew , df_crew_aux[\"idMovies\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_director_aux = df_crew[df_crew[\"nameJob\"] == \"Director\"]\n",
    "df_movies_director = df_director_aux[[\"idMovies\", \"idCrew\"]]\n",
    "df_movies_director.to_parquet(\"DataSet/Relation_Director_Movies.parquet\", engine= \"pyarrow\", index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_director = df_director_aux[[\"idCrew\", \"nameCrew\"]].drop_duplicates().reset_index(drop=True)\n",
    "df_director.to_parquet(\"DataSet/Director_Movies.parquet\", engine= \"pyarrow\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_PI_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
